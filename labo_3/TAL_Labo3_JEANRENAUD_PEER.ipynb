{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://iict-space.heig-vd.ch/apu/wp-content/uploads/sites/21/2022/01/2020-slim.png\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 3 : Analyse syntaxique du français\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "1. Utiliser un analyseur syntaxique **en constituants** pour extraire tous les groupes nominaux d'un texte.\n",
    "1. Appliquer un analyseur syntaxique **de dépendances** sur des données de test en français et calculer son score.\n",
    "1. Entraîner l'analyseur **de dépendances** sur des données adaptées et mesurer si les performances se sont améliorées ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tUtiliser un analyseur syntaxique en constituants pour extraire les groupe nominaux\n",
    "\n",
    "Vous utiliserez l'analyseur syntaxique en constituants appelé `LexicalizedParser` fourni parmi les outils CoreNLP de Stanford, et [documenté ici](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/parser/lexparser/LexicalizedParser.html).  \n",
    "\n",
    "\n",
    "* **code Java** : fichier `stanford-corenlp-3.9.2.jar` (8 Mo) fourni sur Cyberlearn\n",
    "* **modèle** : fichier `frenchFactored.ser.gz` (4 Mo) fourni sur Cyberlearn\n",
    "* **données** : fichier `exemple.txt` fourni sur Cyberlearn\n",
    "\n",
    "a. Veuillez écrire la ligne de commande (java) qui effecte l'analyse syntaxique en constituants du texte `exemple.txt`. Choisissez 'oneline' comme format et écrivez les résultats dans un ficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoked on Mon Mar 27 11:44:21 CEST 2023 with arguments: -writeOutputFiles -outputFormat oneline -v frenchFactored.ser exemple.txt\n",
      "Loading parser from serialized file frenchFactored.ser ... done [2.1 sec].\n",
      "Grammar\tStates\tTags\tWords\tUnaryR\tBinaryR\tTaggings\n",
      "Grammar\t8711\t295\t29038\t1992\t33274\t41024\n",
      "ParserPack is edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams\n",
      "Lexicon is edu.stanford.nlp.parser.lexparser.BaseLexicon\n",
      "Tags are: [0=CLS-VN,1=V-VN,2=PUNC-comma,3=P-PP,4=DET-NP,5=NPP-NP,6=CC-COORD,7=NC-NP,8=P-PP-n,9=N-MWN,10=ADJ-MWN,11=P-de2-PP-n,12=ADJ-AP,13=PUNC,14=DET-MWN,15=ADJ-NP,16=ADJ-COORD,17=.$$.,18=P-de2-MWN,19=C-MWN,20=VPP-VN,21=PUNC-fs,22=N-NP,23=VPP-VPpart,24=PROREL-NP,25=ADV-Srel,26=ADV-SENT,27=P-de2-PP,28=PRO-SENT,29=PRO-NP,30=PRO-Srel,31=P-MWP,32=P-VPinf,33=CLO-VN,34=VINF-VN,35=P-de2-VPinf,36=ADV-VPpart,37=PUNC-colon,38=P-MWADV,39=N-MWADV,40=DET-MWP,41=N-MWP,42=P-de2-MWP,43=V-MWP,44=P-MWN,45=CLR-VN,46=CS-Ssub,47=ADV-VN,48=ADV-AdP,49=CLR-VPpart,50=VPR-VPpart,51=ADJ-MWADV,52=NC-AP,53=P-de2-MWADV,54=ADV-MWADV,55=ADV-AP,56=ADV-PP,57=VINF-VPinf,58=ADV-NP,59=P-de2-NP,60=ADJ-MWA,61=PREF-NP,62=PUNC-quest,63=ADV-MWC,64=C-MWC,65=ADV-Ssub,66=ADV-VPinf,67=DETWH-NP,68=VPP-VPinf,69=DET-MWADV,70=ADV-COORD,71=ADV-MWP,72=V-MWV,73=ADJ-MWV,74=N-MWV,75=ET-MWN,76=DET-MWD,77=DET-COORD,78=VPR-VN,79=VS-VN,80=PRO-VN,81=P-VPpart,82=ADV-Sint,83=ADJ-PP,84=PRO-PP,85=PROREL-PP,86=P-MWC,87=DET-MWV,88=PRO-MWPRO,89=ADV-MWPRO,90=VPP-COORD,91=ET-PP,92=ADVWH-SENT,93=ET-MWA,94=ET-NP,95=P-AdP,96=N-MWD,97=P-de2-MWD,98=ADJ-MWPRO,99=ET-MWADV,100=C-MWADV,101=N-VPpart,102=ET-COORD,103=V-MWN,104=ADJ-AdP,105=PRO-MWN,106=DET-MWPRO,107=N-MWPRO,108=PRO-VPinf,109=P-de2-MWA,110=DET-MWA,111=N-MWA,112=P-MWA,113=N-MWC,114=V-VN-infinitive,115=ADJWH-NP,116=P-MWV,117=CL-MWADV,118=V-MWADV,119=VIMP-VN,120=CL-MWP,121=C-MWP,122=PRO-MWP,123=ADV-MWV,124=P-de2-MWC,125=ADJWH-AP,126=PROREL-Ssub,127=N-SENT,128=N-AP,129=ADJ-SENT,130=PREF-COORD,131=V-VPpart,132=NC-SENT,133=ADV-MWN,134=PROWH-PP,135=ET-SENT,136=ADJ-Ssub,137=ADJ-MWP,138=V-MWC,139=PROREL-Srel,140=NC-COORD,141=I-SENT,142=CS-NP,143=NC-PP,144=P-Ssub,145=CL-MWC,146=DET-MWC,147=PRO-MWC,148=CC-SENT,149=CLO-NP,150=VPP-NP,151=CS-SENT,152=P-de2-AdP,153=P-NP,154=PROWH-NP,155=VPP-AP,156=P-AP,157=ADVWH-Ssub,158=DET-VN,159=N-PP,160=P-de2-COORD,161=P-COORD,162=PREF-AP,163=CC-Sint,164=CC-AP,165=ADJ-VN,166=CS-AP,167=V-MWA,168=ADV-MWA,169=ADJ-MWC,170=ADJ-MWD,171=PRO-MWADV,172=CS-Srel,173=ADVWH-VPinf,174=ET-MWET,175=VPR-NP,176=CS-VPinf,177=CLR-VPinf,178=PROWH-Ssub,179=ADVWH-NP,180=ADV-MWD,181=PREF-MWN,182=DET-PP,183=DET-AP,184=CLO-VPinf,185=P-de2-MWV,186=DET-AdP,187=ET-AP,188=ADVWH-Sint,189=VPP-SENT,190=C-MWD,191=C-MWA,192=DET-MWCL,193=CL-MWCL,194=PREF-VPpart,195=P-de2-AP,196=P-Sint,197=DET-Sint,198=NC-Sint,199=ADJWH-Ssub,200=DET-SENT,201=CL-MWPRO,202=CC-PP,203=ADJWH-SENT,204=I-VN,205=V-MWPRO,206=V-MWD,207=PRO-MWD,208=ADVWH-COORD,209=C-MWPRO,210=NPP-VPpart,211=CLS-NP,212=PRO-COORD,213=VPP-AdP,214=CLO-VPpart,215=ADJ-VPinf,216=CS-COORD,217=ADJ-VPpart,218=NC-VN,219=P-SENT,220=I-COORD,221=P-de2-MWPRO,222=DET-MWI,223=N-MWI,224=ADVWH-PP,225=P-VN,226=NPP-PP,227=CLS-PP,228=CLO-PP,229=V-PP,230=I-NP,231=V-NP,232=VS-COORD,233=VINF-COORD,234=P-Srel,235=PROWH-Srel,236=ADJ-Srel,237=P-de2-Ssub,238=PROREL-VN,239=P-de2-VPpart,240=NC-VPpart,241=V-VN-participle,242=CC-NP,243=PRO-MWV,244=P-MWPRO,245=NC-Srel,246=PRO-Ssub,247=ADVWH-AdP,248=I-MWN,249=VINF-NP,250=VINF-PP,251=I-Sint,252=I-Ssub,253=CL-VN,254=NPP-COORD,255=I-Srel,256=DET-VPpart,257=ET-VPpart,258=P-MWI,259=CS-VPpart,260=VPP-Ssub,261=CL-MWV,262=V-VPinf,263=ADVWH-Srel,264=NC-VPinf,265=NPP-Ssub,266=NPP-SENT,267=CLR-COORD,268=PREF-PP,269=C-MWV,270=NPP-AP,271=PRO-AP,272=V-SENT,273=CLS-SENT,274=V-AP,275=DET-MWET,276=CL-MWN,277=P-de2-VN,278=ADJWH-COORD,279=DET-VPinf,280=PROWH-SENT,281=CLO-SENT,282=V-Srel,283=PREF-AdP,284=PRO-VPpart,285=PRO-AdP,286=V-Ssub,287=CLO-Ssub,288=NC-AdP,289=N-Srel,290=VPR-COORD,291=CS-Sint,292=VPP-Sint,293=A-MWN,294=VPP-Srel]\n",
      "Options parameters:\n",
      "useUnknownWordSignatures 1\n",
      "smoothInUnknownsThreshold 100\n",
      "smartMutation false\n",
      "useUnicodeType false\n",
      "unknownSuffixSize 2\n",
      "unknownPrefixSize 1\n",
      "flexiTag false\n",
      "useSignatureForKnownSmoothing false\n",
      "wordClassesFile null\n",
      "parserParams edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams\n",
      "forceCNF false\n",
      "doPCFG true\n",
      "doDep true\n",
      "freeDependencies false\n",
      "directional true\n",
      "genStop true\n",
      "distance true\n",
      "coarseDistance false\n",
      "dcTags false\n",
      "nPrune false\n",
      "Test parameters maxLength=559038737 preTag=false outputFormat=oneline outputFormatOptions= printAllBestParses=false testingThreads=1 quietEvaluation=false\n",
      "FrenchTreebankParserParams\n",
      "Sentence final words are: [., !, ?]\n",
      "File encoding is: UTF-8\n",
      "Parsing file: exemple.txt\n",
      "edu.stanford.nlp.international.french.process.FrenchLexer: Invalid options key in constructor: splitContractions\n",
      "Parsing [sent. 1 len. 12]: Les gares voyageurs sont en fait des ensembles fonctionnels plus larges .\n",
      "Starting pcfg parse. Time elapsed: 2180 ms\n",
      "Created PCFG parser arrays of size 14\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 7 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 4 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 37 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 43 ms\n",
      "Starting dependency parse. Time elapsed: 26 ms\n",
      "Created dparser arrays of size 14\n",
      "Initializing...\n",
      "done. Time elapsed: 397 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 9 ms\n",
      "Dep  parsing 13 words (incl. stop): insideScore -91.779305\n",
      "Starting outsides...\n",
      "done. Time elapsed: 42 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 7 ms\n",
      "Starting combined parse. Time elapsed: 35 ms\n",
      "Terminals (# of tag edges in chart): 97\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "8 \n",
      "9 \n",
      "12 \n",
      "13 \n",
      "Found goal!\n",
      "Comb iScore -177.5945676269264\n",
      "Done, parse found. Time elapsed: 52 ms\n",
      "Built items:      371\n",
      "Built hooks:      24\n",
      "Built edges:      347\n",
      "Extracted items:  50\n",
      "Extracted hooks:  12\n",
      "Extracted edges:  38\n",
      "Parsing [sent. 2 len. 20]: Elles regroupent toutes les fonctions centrées sur l' accès à le train et l' achat des titres de transport .\n",
      "Starting pcfg parse. Time elapsed: 3 ms\n",
      "Created PCFG parser arrays of size 22\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 12 ms\n",
      "Unknown words: 1 [ centrées { 2 2 2 2 2 2 2 2 } ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 7 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 191 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 113 ms\n",
      "Starting dependency parse. Time elapsed: 17 ms\n",
      "Created dparser arrays of size 22\n",
      "Initializing...\n",
      "done. Time elapsed: 1129 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 66 ms\n",
      "Dep  parsing 21 words (incl. stop): insideScore -110.37243\n",
      "Starting outsides...\n",
      "done. Time elapsed: 123 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 1 ms\n",
      "Starting combined parse. Time elapsed: 17 ms\n",
      "Terminals (# of tag edges in chart): 205\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "8 \n",
      "9 \n",
      "11 \n",
      "12 \n",
      "15 \n",
      "16 \n",
      "17 \n",
      "19 \n",
      "20 \n",
      "21 \n",
      "Found goal!\n",
      "Comb iScore -239.27947860325366\n",
      "Done, parse found. Time elapsed: 40 ms\n",
      "Built items:      1129\n",
      "Built hooks:      110\n",
      "Built edges:      1019\n",
      "Extracted items:  162\n",
      "Extracted hooks:  48\n",
      "Extracted edges:  114\n",
      "Parsing [sent. 3 len. 11]: Elles offrent aussi divers services commerciaux liés à le voyage .\n",
      "Starting pcfg parse. Time elapsed: 5 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 2 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 3 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 11 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 14 ms\n",
      "Starting dependency parse. Time elapsed: 3 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 110 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 3 ms\n",
      "Dep  parsing 12 words (incl. stop): insideScore -71.460526\n",
      "Starting outsides...\n",
      "done. Time elapsed: 4 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 2 ms\n",
      "Terminals (# of tag edges in chart): 72\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "6 \n",
      "7 \n",
      "10 \n",
      "11 \n",
      "12 \n",
      "Found goal!\n",
      "Comb iScore -150.35814732162726\n",
      "Done, parse found. Time elapsed: 4 ms\n",
      "Built items:      356\n",
      "Built hooks:      24\n",
      "Built edges:      332\n",
      "Extracted items:  53\n",
      "Extracted hooks:  13\n",
      "Extracted edges:  40\n",
      "Parsing [sent. 4 len. 16]: Pour certaines gares , le passage de nombreux voyageurs justifie l' installation de fonctions annexes .\n",
      "Starting pcfg parse. Time elapsed: 1 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 5 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 1 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 35 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 43 ms\n",
      "Starting dependency parse. Time elapsed: 5 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 198 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 10 ms\n",
      "Dep  parsing 17 words (incl. stop): insideScore -111.471855\n",
      "Starting outsides...\n",
      "done. Time elapsed: 18 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 4 ms\n",
      "Terminals (# of tag edges in chart): 129\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "12 \n",
      "13 \n",
      "16 \n",
      "17 \n",
      "Found goal!\n",
      "Comb iScore -216.89658187466193\n",
      "Done, parse found. Time elapsed: 8 ms\n",
      "Built items:      609\n",
      "Built hooks:      31\n",
      "Built edges:      578\n",
      "Extracted items:  69\n",
      "Extracted hooks:  16\n",
      "Extracted edges:  53\n",
      "Parsing [sent. 5 len. 13]: Il s' agit , par exemple , de commerces et services variés .\n",
      "Starting pcfg parse. Time elapsed: 5 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 2 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 12 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 15 ms\n",
      "Starting dependency parse. Time elapsed: 3 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 134 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 5 ms\n",
      "Dep  parsing 14 words (incl. stop): insideScore -65.511024\n",
      "Starting outsides...\n",
      "done. Time elapsed: 7 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 7 ms\n",
      "Terminals (# of tag edges in chart): 84\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "6 \n",
      "7 \n",
      "12 \n",
      "13 \n",
      "14 \n",
      "Found goal!\n",
      "Comb iScore -139.563132711281\n",
      "Done, parse found. Time elapsed: 8 ms\n",
      "Built items:      692\n",
      "Built hooks:      19\n",
      "Built edges:      673\n",
      "Extracted items:  56\n",
      "Extracted hooks:  13\n",
      "Extracted edges:  43\n",
      "Parsing [sent. 6 len. 12]: Les gares peu importantes sont appelées haltes ou points d' arrêt .\n",
      "Starting pcfg parse. Time elapsed: 1 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 2 ms\n",
      "Unknown words: 1 [ haltes { 2 2 2 2 2 2 } ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 2 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 11 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 11 ms\n",
      "Starting dependency parse. Time elapsed: 3 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 125 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 2 ms\n",
      "Dep  parsing 13 words (incl. stop): insideScore -82.78028\n",
      "Starting outsides...\n",
      "done. Time elapsed: 4 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 2 ms\n",
      "Terminals (# of tag edges in chart): 82\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "7 \n",
      "8 \n",
      "12 \n",
      "13 \n",
      "Found goal!\n",
      "Comb iScore -173.4885513857007\n",
      "Done, parse found. Time elapsed: 4 ms\n",
      "Built items:      542\n",
      "Built hooks:      19\n",
      "Built edges:      523\n",
      "Extracted items:  55\n",
      "Extracted hooks:  13\n",
      "Extracted edges:  42\n",
      "Parsing [sent. 7 len. 23]: Le train est un matériel roulant ferroviaire assurant le transport de personnes ou de marchandises sur une ligne de chemin de fer .\n",
      "Starting pcfg parse. Time elapsed: 3 ms\n",
      "Created PCFG parser arrays of size 25\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 92 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 2 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 100 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 87 ms\n",
      "Starting dependency parse. Time elapsed: 7 ms\n",
      "Created dparser arrays of size 25\n",
      "Initializing...\n",
      "done. Time elapsed: 1173 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 35 ms\n",
      "Dep  parsing 24 words (incl. stop): insideScore -143.68752\n",
      "Starting outsides...\n",
      "done. Time elapsed: 69 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 2 ms\n",
      "Terminals (# of tag edges in chart): 229\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "8 \n",
      "15 \n",
      "18 \n",
      "19 \n",
      "20 \n",
      "21 \n",
      "23 \n",
      "24 \n",
      "Found goal!\n",
      "Comb iScore -294.20771940888426\n",
      "Done, parse found. Time elapsed: 17 ms\n",
      "Built items:      1100\n",
      "Built hooks:      56\n",
      "Built edges:      1044\n",
      "Extracted items:  116\n",
      "Extracted hooks:  28\n",
      "Extracted edges:  88\n",
      "Parsing [sent. 8 len. 19]: Par extension , on appelle train le service que constitue chacun de ces transports , réguliers ou non .\n",
      "Starting pcfg parse. Time elapsed: 1 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 3 ms\n",
      "Unknown words: 0 [ ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 1 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 35 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 29 ms\n",
      "Starting dependency parse. Time elapsed: 5 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 230 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 7 ms\n",
      "Dep  parsing 20 words (incl. stop): insideScore -134.2676\n",
      "Starting outsides...\n",
      "done. Time elapsed: 23 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 0 ms\n",
      "Terminals (# of tag edges in chart): 142\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "8 \n",
      "9 \n",
      "10 \n",
      "12 \n",
      "15 \n",
      "16 \n",
      "17 \n",
      "19 \n",
      "20 \n",
      "Found goal!\n",
      "Comb iScore -265.17261414124505\n",
      "Done, parse found. Time elapsed: 9 ms\n",
      "Built items:      1450\n",
      "Built hooks:      147\n",
      "Built edges:      1303\n",
      "Extracted items:  276\n",
      "Extracted hooks:  79\n",
      "Extracted edges:  197\n",
      "Parsing [sent. 9 len. 14]: Le train est un mode de transport , s' effectuant sur voie ferrée .\n",
      "Starting pcfg parse. Time elapsed: 1 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 1 ms\n",
      "Unknown words: 1 [ ferrée { 2 2 2 2 2 2 } ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 1 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 19 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 20 ms\n",
      "Starting dependency parse. Time elapsed: 1 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 146 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 6 ms\n",
      "Dep  parsing 15 words (incl. stop): insideScore -79.911514\n",
      "Starting outsides...\n",
      "done. Time elapsed: 13 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 0 ms\n",
      "Starting combined parse. Time elapsed: 0 ms\n",
      "Terminals (# of tag edges in chart): 120\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "5 \n",
      "6 \n",
      "11 \n",
      "12 \n",
      "14 \n",
      "15 \n",
      "Found goal!\n",
      "Comb iScore -166.83302283716648\n",
      "Done, parse found. Time elapsed: 4 ms\n",
      "Built items:      539\n",
      "Built hooks:      24\n",
      "Built edges:      515\n",
      "Extracted items:  62\n",
      "Extracted hooks:  14\n",
      "Extracted edges:  48\n",
      "Parsing [sent. 10 len. 48]: Étymologiquement parlant , le mot train désigne une rame de wagons de marchandises ou de voitures de passagers tractée par à le moins une locomotive , par opposition à les rames automotrices -LRB- catégorie dont fait partie le TGV -RRB- ou autorails qui assurent leur propre propulsion .\n",
      "Starting pcfg parse. Time elapsed: 1 ms\n",
      "Created PCFG parser arrays of size 50\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 35 ms\n",
      "Unknown words: 5 [ Étymologiquement { 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 } rame { 2 2 2 2 } tractée { 2 2 2 2 2 2 2 } rames { 2 2 2 2 2 } autorails { 2 2 2 2 2 2 2 2 2 } ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 3 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 587 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 710 ms\n",
      "Starting dependency parse. Time elapsed: 19 ms\n",
      "Created dparser arrays of size 50\n",
      "Initializing...\n",
      "done. Time elapsed: 32475 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 769 ms\n",
      "Dep  parsing 49 words (incl. stop): insideScore -315.81314\n",
      "Starting outsides...\n",
      "done. Time elapsed: 1154 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 6 ms\n",
      "Starting combined parse. Time elapsed: 41 ms\n",
      "Terminals (# of tag edges in chart): 430\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "8 \n",
      "10 \n",
      "13 \n",
      "14 \n",
      "15 \n",
      "16 \n",
      "17 \n",
      "18 \n",
      "19 \n",
      "20 \n",
      "21 \n",
      "22 \n",
      "23 \n",
      "24 \n",
      "25 \n",
      "31 \n",
      "32 \n",
      "41 \n",
      "42 \n",
      "45 \n",
      "46 \n",
      "48 \n",
      "49 \n",
      "Found goal!\n",
      "Comb iScore -690.5127912842654\n",
      "Done, parse found. Time elapsed: 1208 ms\n",
      "Built items:      24940\n",
      "Built hooks:      12795\n",
      "Built edges:      12145\n",
      "Extracted items:  6939\n",
      "Extracted hooks:  3112\n",
      "Extracted edges:  3827\n",
      "Parsing [sent. 11 len. 40]: Cependant , dans l' usage courant , le mot train désigne n' importe quelle circulation ferroviaire , quelle que soit sa composition , depuis le plus simple autorail local jusqu'aux longs trains de grandes lignes ou de transports industriels .\n",
      "Starting pcfg parse. Time elapsed: 11 ms\n",
      "Initializing PCFG...\n",
      "done. Time elapsed: 57 ms\n",
      "Unknown words: 2 [ autorail { 2 2 2 2 2 2 2 2 } jusqu'aux { 2 2 2 2 2 24 2 2 2 } ]\n",
      "Starting filters...\n",
      "done. Time elapsed: 18 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 348 ms\n",
      "Starting outsides...\n",
      "done. Time elapsed: 318 ms\n",
      "Starting dependency parse. Time elapsed: 17 ms\n",
      "Initializing...\n",
      "done. Time elapsed: 6597 ms\n",
      "Starting insides...\n",
      "done. Time elapsed: 189 ms\n",
      "Dep  parsing 41 words (incl. stop): insideScore -271.75247\n",
      "Starting outsides...\n",
      "done. Time elapsed: 384 ms\n",
      "Starting half-filters...\n",
      "done. Time elapsed: 1 ms\n",
      "Starting combined parse. Time elapsed: 6 ms\n",
      "Terminals (# of tag edges in chart): 318\n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "7 \n",
      "8 \n",
      "9 \n",
      "10 \n",
      "12 \n",
      "13 \n",
      "14 \n",
      "15 \n",
      "16 \n",
      "20 \n",
      "21 \n",
      "22 \n",
      "25 \n",
      "26 \n",
      "29 \n",
      "30 \n",
      "33 \n",
      "34 \n",
      "38 \n",
      "39 \n",
      "40 \n",
      "41 \n",
      "Found goal!\n",
      "Comb iScore -588.1539785968284\n",
      "Done, parse found. Time elapsed: 1216 ms\n",
      "Built items:      41087\n",
      "Built hooks:      16291\n",
      "Built edges:      24796\n",
      "Extracted items:  12106\n",
      "Extracted hooks:  4838\n",
      "Extracted edges:  7268\n",
      "Parsed file: exemple.txt [11 sentences].\n",
      "Parsed 228 words in 11 sentences (4,41 wds/sec; 0,21 sents/sec).\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-corenlp-3.9.2.jar -mx5g edu.stanford.nlp.parser.lexparser.LexicalizedParser -writeOutputFiles -outputFormat oneline -v frenchFactored.ser exemple.txt > output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Importez le fichier de résultats du LexicalizedParser comme une liste d'arbres, en utilisant la classe `BracketParseCorpusReader` de NLTK.  Chaque ligne contenant une analyse syntaxique sera importée comme un objet `Tree` de NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.bracket_parse import BracketParseCorpusReader\n",
    "root = '.'\n",
    "forest = BracketParseCorpusReader(root, 'exemple.txt.stp').parsed_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cherchez dans la [documentation](https://www.nltk.org/_modules/nltk/tree.html#Tree) de `Tree` une fonction d'affichage, et affichez l'arbre de la première ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   ROOT                                                \n",
      "                                    |                                                   \n",
      "                                   SENT                                                \n",
      "       _____________________________|_______________________________________________    \n",
      "      NP             |         |                           NP                       |  \n",
      "  ____|_______       |         |          _________________|_____________           |   \n",
      " |    |       AP     VN      MWADV       |      |          AP            AP         |  \n",
      " |    |       |      |     ____|____     |      |          |         ____|____      |   \n",
      "DET   NC     ADJ     V    P         N   DET     NC        ADJ      ADV       ADJ   PUNC\n",
      " |    |       |      |    |         |    |      |          |        |         |     |   \n",
      "Les gares voyageurs sont  en       fait des ensembles fonctionnels plus     larges  .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  Écrivez le code qui extrait les groupes nominaux de toutes les phrases (en anglais: Noun Phrases), et qui affiche les 5 les plus fréquents avec leurs nombres d'occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Veuillez répéter l'expérience avec un texte plus long (un texte en français du projet Gutenberg) et afficher les 20 groupes nominaux les plus fréquents.  Veuillez indiquer approximativement combien de temps a pris l'analyse syntaxique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse de dépendances\n",
    "\n",
    "Dans cette partie, vous utiliserez le [Stanford Dependency Parser](https://nlp.stanford.edu/software/nndep.html), un analyseur fondé sur un réseau de neurones.\n",
    "\n",
    "* **code Java** : fichier `stanford-corenlp-3.9.2.jar` (8 Mo) fourni sur Cyberlearn (note: on peut le télécharger avec un [package fourni par Stanford](https://nlp.stanford.edu/software/lex-parser.html) ou depuis le [site Maven de Stanford CoreNLP](https://search.maven.org/artifact/edu.stanford.nlp/stanford-corenlp/3.9.2/jar))\n",
    "* **modèle** : fichier `UD_French.gz` (10 Mo) fourni sur Cyberlearn (note: plusieurs modèles sont disponibles sur le site Maven, dont un package pour le français de 272 MB, mais ici vous aurez seulement besoin du modèle UD pour Universal Dependencies)\n",
    "* **données** : les mêmes que pour le labo 2, disponibles dans [l'archive ZIP fournie par l'enseignant](https://drive.switch.ch/index.php/s/5ZNllZOApTWHGwH) (mot de passe = reference).  Ces textes en français proviennent du projet [Universal Dependencies (UD)](https://github.com/UniversalDependencies/UD_French-GSD).  Le fichier `fr-ud-train.conllu3` est destiné à l'entraînement, `fr-ud-dev.conllu3` à la validation, et `fr-ud-test.conllu3` à l'évaluation finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer les tâches suivantes, utilisez la [documentation](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/parser/nndep/DependencyParser.html) et regardez surtout le `main()` et les exemples données à la fin.\n",
    "\n",
    "a. Exécuter le parser en Java (avec une commande externe `!java -cp ...` comme au labo 2) en l'appliquant au fichier UD de *test* en français.  Écrivez le résultat détaillé dans un fichier plutôt qu'à l'écran.  Quels sont les deux scores obtenus et que signifient-ils ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour tester le parser avec le modèle pré-entraîné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraîner l'analyseur de dépendances\n",
    "\n",
    "a. Veuillez entraîner l'analyseur en suivant les indications suivantes:\n",
    "* donnez un nouveau nom au modèle qui sera créé (ne pas écraser l'ancien)\n",
    "* utilisez à la fois `train` et `dev` comme indiqué dans la documentation\n",
    "* évitez un output trop verbeux en le redirigeant vers un fichier `output.txt` (ajoutez `>output.txt 2>&1` à la commande)\n",
    "* plusieurs options indiquées dans la documentation peuvent être utiles\n",
    "  * `-wordCutOff 3` pour traiter seulement les mots apparaissant plus de 3 fois, ce qui évite en particulier le problème des nombres écrits avec un espace (apparaissant 1 fois)\n",
    "  * `-trainingThreads 4` pour utiliser pleinement votre processeur : indiquez le maximum selon votre modèle\n",
    "  * `-maxIter 5000` pour arrêter l'entraînement après 5000 itérations (essayez d'abord beaucoup moins pour vous faire une idée du temps, puis si vous le pouvez, allez plus loin que 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour entraîner l'analyseur sur le fichier 'train' et créer un nouveau modèle.\n",
    "# Pour ne pas bloquer votre notebook, vous pouvez l'exécuter dans l'invite de commandes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Quels sont les scores (sur les données de test) du système que vous avez entraîné ?  Comment se comparent-ils avec ceux du système par défaut ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour tester l'analyseur avec le nouveau modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. En traitant le fichier de logs du parser (après l'entraînement), collectez les scores UAS obtenus sur l'ensemble de développement (ou validation).  Affichez sur un graphe l'évolution du score au cours de l'entraînement.  À quelle itération obtenez-vous la valeur maximale de ce score ? Le nombre d'itérations de l'entraînement vous semble-t-il suffisant  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code qui extrait les valeurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez ici le code affichant les deux courbes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 3\n",
    "\n",
    "Merci de nettoyer votre feuille et de la sauvegarder.  Puis soumettez-la sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
