{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 6\n",
    "# Classification de dépêches d’agence avec NLTK\n",
    "## Nelson Jeanrenaud & Vincent Peer\n",
    "## 11.06.2023\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "L’objectif de ce labo est de réaliser des expériences de classification de documents sous NLTK avec le\n",
    "corpus de dépêches Reuters. Le labo est à effectuer en binôme. Le labo sera jugé sur la qualité des\n",
    "expériences et sur la discussion des différentes options explorées. Vous devez remettre un notebook\n",
    "Jupyter présentant vos choix, votre code, vos résultats et les discussions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description des expériences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **L’objectif général** est d’explorer au moins deux aspects parmi les choix qui se posent lors de\n",
    "la création d’un système probabiliste de classification de textes.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Données** : les dépêches du corpus Reuters, tel qu’il est fourni par NLTK. Vous respecterez\n",
    "notamment la division en données d’entraînement (train) et données de test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Hyper-paramètres** : veuillez étudier au moins deux hyperparamètres. Pour chacun, veuillez\n",
    "comparer au moins deux valeurs et indiquer laquelle fournit le meilleur score. Vous pourrez\n",
    "choisir parmi les hyperparamètres suivants :  \n",
    "• options de prétraitement des textes : stopwords, lemmatisation, tout en minuscules.  \n",
    "• options de représentation : présence/absence de mots indicateurs, nombre de mots  \n",
    "indicateurs ; présence/absence/nombre de bigrammes, trigrammes ; autres traits :\n",
    "longueur de la dépêche, rapport tokens/types.  \n",
    "• classifieurs et leurs paramètres : divers choix possibles (voir la documentation NLTK)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Veuillez définir et entraîner **trois classifieurs binaires** : chacun prédit si une dépêche est\n",
    "étiquetée ou non avec la catégorie respective. Le premier classifieur binaire sera pour\n",
    "l’étiquette ‘money-fx’, le deuxième concernera ‘grain’, et le troisième sera pour ‘nat-gas’."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pour chacun des classifieurs, optimisez les hyperparamètres sans toucher aux données de test\n",
    "NLTK. Divisez les données d’entraînement NLTK en 80% train et 20% dev, et choisissez les\n",
    "options qui donnent les meilleurs scores sur dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['CSCE', 'TO', 'PUT', 'ADDITIONAL', 'MARGIN', 'ON', ...], ['cocoa'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('reuters')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "# Extract fileids from the reuters corpus\n",
    "file_ids = reuters.fileids()\n",
    "documents = []\n",
    "\n",
    "# Loop through each file id and collect each files categories and tokenized words\n",
    "for file in file_ids:\n",
    "    words = reuters.words(file)\n",
    "    documents.append((words, reuters.categories(file)))\n",
    "\n",
    "shuffle(documents)\n",
    "documents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pour la classification des documents, nous avons décidé d'utiliser la fréquence des mots. Nous avons donc commencé par déterminer la fréquence des mots du dataset, puis les 2000 mots les plus fréquents sont retournés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_frequence):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_frequence:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def most_freq_words(documents, limit=2000):\n",
    "    all_words = nltk.FreqDist(w\n",
    "        for document in documents\n",
    "        for w in document[0]\n",
    "    )\n",
    "    return list(all_words)[:limit]\n",
    "\n",
    "def create_dataset(documents, tag, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag in document[1]))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    split_ratio = 0.6\n",
    "    split_ratio2 = 0.8\n",
    "    \n",
    "    split = int(len(dataset) * split_ratio)\n",
    "    split2 = int(len(dataset) * split_ratio2)\n",
    "\n",
    "    return (dataset[:split], dataset[split:split2], dataset[split2:])\n",
    "\n",
    "def best_classifier(documents, tag, dataset_creator, hyperparams):\n",
    "    print('Finding best classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = dataset_creator(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)\n",
    "\n",
    "def ref_test_sets(testset, classifier):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "\n",
    "    for i, (feats, label) in enumerate(testset):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "    return refsets, testsets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pour les hyperparamètres, nous avons choisi de supprimer les stopwords, la lemmatisation et de tout mettre en minuscule. En plus de tester chaque hyperparamètre indépendamment, nous avons aussi tenté d'appliquer plusieurs hyperparamètres en même temps, par exemple lemmatiser et supprimer les stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents money-fx\n",
    ">Si l'on compare chaque hyperparamètre seul, on peut voir que la suppression des stopwords offre un meilleur résultat que les autres. On remarque aussi que le fait de combiner la mise en minuscule avec les autres hyperparamètres améliore les scores. Et finalement, on remarque que combiner les trois hyperparamètres offre le meilleur score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for money-fx\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 87.44%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 88.65%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 87.95%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 91.75%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 92.26%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 90.73%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 88.51%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 92.68%\n"
     ]
    }
   ],
   "source": [
    "classifier_moneyfx, moneyfx_testset = best_classifier(documents, 'money-fx', create_dataset, hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents grain\n",
    ">Si l'on compare chaque hyperparamètres seul, on peut voir que cette fois la suppression des stopwords est nettement meilleure que les autres. Le fait de combiner la suppression des stopwords avec les autres hyperparamètres améliore nettement les scores. Et finalement, on remarque que combiner les trois hyperparamètres améliore le score (accuracy) du classifieur, mais qu'il n'est pas le meilleur. Ici le meilleur classifieur est celui qui combine la supression des stopwords et la mise en minuscule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for grain\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 88.23%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 85.50%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 86.47%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 92.17%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 92.54%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 90.69%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 87.63%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 92.17%\n"
     ]
    }
   ],
   "source": [
    "classifier_grain, grain_testset = best_classifier(documents, 'grain', create_dataset, hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents nat-gas\n",
    ">Pour ce classifieur nous nous retrouvons plus ou moins dans la même situation que le classifieur grain. C'est-à-dire que le meilleur classifieur avec un seul hyperparamètre et aussi celui qui supprime les stopwords. La combinaison des hyperparamètres augmente bien le score surout pour la combinaison stopword-minuscule qui offre le meilleur score. Cette fois, la combinaison des 3 hypermparamètres donne un résultat un peu en dessous des combinaison à deux paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for nat-gas\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 87.26%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 89.99%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 88.37%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 91.66%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 93.23%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 92.72%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 91.47%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 91.84%\n"
     ]
    }
   ],
   "source": [
    "classifier_natgas, natgas_testset = best_classifier(documents, 'nat-gas', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "moneyfx_refsets, moneyfx_testsets = ref_test_sets(moneyfx_testset, classifier_moneyfx)\n",
    "grain_refsets, grain_testsets = ref_test_sets(grain_testset, classifier_grain)\n",
    "natgas_refsets, natgas_testsets = ref_test_sets(natgas_testset, classifier_natgas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Veuillez donner les scores de rappel, précision et f-mesure de chacun des trois classifieurs,\n",
    "avec les meilleurs hyperparamètres, sur les données de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money-fx:\n",
      "---------\n",
      "Precision: 0.38596491228070173\n",
      "Recall: 0.7801418439716312\n",
      "F-mesure: 0.5164319248826291\n",
      "\n",
      "Grain:\n",
      "---------\n",
      "Precision: 0.3475177304964539\n",
      "Recall: 0.9333333333333333\n",
      "F-mesure: 0.5064599483204134\n",
      "\n",
      "Nat-gas:\n",
      "---------\n",
      "Precision: 0.0663265306122449\n",
      "Recall: 0.7222222222222222\n",
      "F-mesure: 0.12149532710280375\n"
     ]
    }
   ],
   "source": [
    "print('Money-fx:')\n",
    "print('---------')\n",
    "print('Precision:', precision(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('Recall:'   , recall(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('F-mesure:' , f_measure(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Grain:')\n",
    "print('---------')\n",
    "print('Precision:', precision(grain_refsets[True], grain_testsets[True]))\n",
    "print('Recall:'   , recall(grain_refsets[True], grain_testsets[True]))\n",
    "print('F-mesure:' , f_measure(grain_refsets[True], grain_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Nat-gas:')\n",
    "print('---------')\n",
    "print('Precision:', precision(natgas_refsets[True], natgas_testsets[True]))\n",
    "print('Recall:'   , recall(natgas_refsets[True], natgas_testsets[True]))\n",
    "print('F-mesure:' , f_measure(natgas_refsets[True], natgas_testsets[True]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regardant la précision, le rappel et la F-Mesure de tout nos classifieurs, on remarque qu'ils ont un problème de précision. C'est-à-dire qu'ils n'arrivent pas à correctement classifier les documents du type que l'on souhaite classifier. Pour le rappel, on voit que les résultats sont corrects mais pas excellent, ce qui veut dire qu'ils sont tout de même globalement capables de classifier les documents qui ne sont pas ceux que l'on souhaite classifier. Le F-Mesure indique que les deux premiers modèles sont aux alentours de 50% ce qui n'est pas non plus une grande performance. Pire encore, le nat-gas a une f-mesure à seuelement 12%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Veuillez définir **un quatrième classifieur multi-classe** qui assigne une étiquette parmi quatre :\n",
    "les trois choisies ci-dessus plus la catégorie ‘other’. Vous devrez nettoyer les données, car un\n",
    "petit nombre de dépêches sont annotées avec plusieurs étiquettes : dans ce cas, gardez\n",
    "seulement la première. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_dataset(documents, tags, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        document_tags = list(set(tags).intersection(document[1]))\n",
    "        tag = 'other' if document_tags == [] else document_tags[0]\n",
    "\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def best_multi_classifier(documents, tag, hyperparams):\n",
    "    print('Finding best milti-classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = create_multi_dataset(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best milti-classifier for ['money-fx', 'grain', 'nat-gas']\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 78.64%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 77.34%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 78.22%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 82.07%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 83.13%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 82.34%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 78.08%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 83.04%\n"
     ]
    }
   ],
   "source": [
    "classifier_multi, multi_testset = best_multi_classifier(documents, ['money-fx', 'grain', 'nat-gas'], hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_refsets, multi_testsets = ref_test_sets(multi_testset, classifier_multi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Veuillez donner les scores de rappel, précision et f-mesure de ce classifieur pour chacune des\n",
    "trois étiquettes choisies. Comment les scores se comparent-ils à ceux des trois classifieurs\n",
    "binaires ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for multiclass classifiers for Money-Fx, Grain, Nat-Gas\n",
      "\n",
      "Money-Fx:\n",
      "---------\n",
      "Precision: 0.4678111587982833\n",
      "Recall: 0.8195488721804511\n",
      "F-mesure: 0.5956284153005464\n",
      "\n",
      "Grain:\n",
      "---------\n",
      "Precision: 0.4713114754098361\n",
      "Recall: 0.9274193548387096\n",
      "F-mesure: 0.625\n",
      "\n",
      "Nat-Gas:\n",
      "---------\n",
      "Precision: 0.15384615384615385\n",
      "Recall: 0.75\n",
      "F-mesure: 0.25531914893617025\n",
      "\n",
      "Other:\n",
      "---------\n",
      "Precision: 0.9757033248081841\n",
      "Recall: 0.8129994672349494\n",
      "F-mesure: 0.8869514675966289\n"
     ]
    }
   ],
   "source": [
    "words = ['money-fx', 'grain', 'nat-gas']\n",
    "print(\"Score for multiclass classifiers for {}\".format(\", \".join(map(lambda i: i.title(), words))))\n",
    "words.append('other')\n",
    "for word in words:\n",
    "    print(\"\")\n",
    "    print('{}:'.format(word.title()))\n",
    "    print('---------')\n",
    "    print('Precision:', precision(multi_refsets[word], multi_testsets[word]))\n",
    "    print('Recall:'   , recall(multi_refsets[word], multi_testsets[word]))\n",
    "    print('F-mesure:' , f_measure(multi_refsets[word], multi_testsets[word]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pour le multiclass, la précision est à nouveau faible mais le rappel est lui très bon. La f-mesure suit les résultats précédents en maintenant un score médiocre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Documentation** : livre NLTK, [chapitre 2](https://www.nltk.org/book/ch02.html) pour accéder au corpus Reuters et le [chapitre 6](https://www.nltk.org/book/ch06.html) pour\n",
    "la classification ; puis http://www.nltk.org/howto/classify.html pour les classifieurs dans\n",
    "NLTK ; enfin, Introduction to Information Retrieval (https://nlp.stanford.edu/IRbook/information-retrieval-book.html), [chapitre 13](https://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html), pour une discussion générale de\n",
    "méthodes de classification, et des exemples de scores obtenus sur certaines étiquettes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoursTAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
